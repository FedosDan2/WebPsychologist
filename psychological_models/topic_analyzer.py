import json
import os
from collections import Counter
import re

class TopicAnalyzer:
    def __init__(self):
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º
        self.topic_keywords = {
            '—Ä–∞–±–æ—Ç–∞': ['—Ä–∞–±–æ—Ç–∞', '–ø—Ä–æ–µ–∫—Ç', '–∑–∞–¥–∞—á–∞', '–¥–µ–¥–ª–∞–π–Ω', '–Ω–∞—á–∞–ª—å–Ω–∏–∫', '–∫–æ–ª–ª–µ–≥–∞', 
                      '–æ—Ç—á—ë—Ç', '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è', '—Å–æ–≤–µ—â–∞–Ω–∏–µ', '–∑–∞—Ä–ø–ª–∞—Ç–∞', '–æ—Ñ–∏—Å', '—É–¥–∞–ª—ë–Ω–∫–∞'],
            
            '—Å–µ–º—å—è': ['—Å–µ–º—å—è', '–¥–µ—Ç–∏', '—Ä–µ–±—ë–Ω–æ–∫', '–º—É–∂', '–∂–µ–Ω–∞', '—Ä–æ–¥–∏—Ç–µ–ª–∏', '–º–∞–º–∞', '–ø–∞–ø–∞',
                     '–±–∞–±—É—à–∫–∞', '–¥–µ–¥—É—à–∫–∞', '—Ä–æ–¥–Ω—ã–µ', '–¥–æ–º–∞—à–Ω–∏–µ', '—Å–µ–º–µ–π–Ω—ã–π'],
            
            '–±—ã—Ç': ['–¥–æ–º', '–∫–≤–∞—Ä—Ç–∏—Ä–∞', '—É–±–æ—Ä–∫–∞', '–≥–æ—Ç–æ–≤–∫–∞', '–ø–æ–∫—É–ø–∫–∏', '–º–∞–≥–∞–∑–∏–Ω', '–µ–¥–∞',
                   '—É–∂–∏–Ω', '–∑–∞–≤—Ç—Ä–∞–∫', '—Å—Ç–∏—Ä–∫–∞', '—Ä–µ–º–æ–Ω—Ç', '–º–µ–±–µ–ª—å', '—Ç–µ—Ö–Ω–∏–∫–∞'],
            
            '–æ—Ç–¥—ã—Ö': ['–æ—Ç–¥—ã—Ö', '–æ—Ç–ø—É—Å–∫', '–∫–∞–Ω–∏–∫—É–ª—ã', '–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ', '–ø–æ–µ–∑–¥–∫–∞', '–º–æ—Ä–µ',
                     '–≥–æ—Ä—ã', '–æ—Ç–µ–ª—å', '–±–∏–ª–µ—Ç—ã', '—ç–∫—Å–∫—É—Ä—Å–∏—è', '—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è', '–∫–∏–Ω–æ', '—Ä–µ—Å—Ç–æ—Ä–∞–Ω'],
            
            '–∑–¥–æ—Ä–æ–≤—å–µ': ['–∑–¥–æ—Ä–æ–≤—å–µ', '–±–æ–ª–µ–∑–Ω—å', '–≤—Ä–∞—á', '–±–æ–ª—å–Ω–∏—Ü–∞', '–ª–µ–∫–∞—Ä—Å—Ç–≤–æ', '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞',
                        '–≥—Ä–∏–ø–ø', '–ø—Ä–æ—Å—Ç—É–¥–∞', '–∞–ø—Ç–µ–∫–∞', '–∞–Ω–∞–ª–∏–∑—ã', '–æ–ø–µ—Ä–∞—Ü–∏—è', '–¥–∏–µ—Ç–∞', '—Å–ø–æ—Ä—Ç'],
            
            '—Ñ–∏–Ω–∞–Ω—Å—ã': ['–¥–µ–Ω—å–≥–∏', '–∑–∞—Ä–ø–ª–∞—Ç–∞', '–±—é–¥–∂–µ—Ç', '—ç–∫–æ–Ω–æ–º–∏—è', '—Ç—Ä–∞—Ç—ã', '–ø–æ–∫—É–ø–∫–∞',
                       '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '–∫—Ä–µ–¥–∏—Ç', '–∏–ø–æ—Ç–µ–∫–∞', '—Å–±–µ—Ä–µ–∂–µ–Ω–∏—è', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏'],
            
            '–ø–ª–∞–Ω—ã': ['–ø–ª–∞–Ω—ã', '—Ü–µ–ª–∏', '–º–µ—á—Ç—ã', '–±—É–¥—É—â–µ–µ', '–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã', '–Ω–∞–º–µ—Ä–µ–Ω–∏—è',
                     '–æ–∂–∏–¥–∞–Ω–∏—è', '—Ä–∞—Å—á–µ—Ç—ã', '—Å—Ç—Ä–∞—Ç–µ–≥–∏—è', '–≥—Ä–∞—Ñ–∏–∫', '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ'],
            
            '–ø—Ä–æ–±–ª–µ–º—ã': ['–ø—Ä–æ–±–ª–µ–º–∞', '—Ç—Ä—É–¥–Ω–æ—Å—Ç—å', '—Å–ª–æ–∂–Ω–æ—Å—Ç—å', '–∑–∞—Ç—Ä—É–¥–Ω–µ–Ω–∏–µ', '–ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–µ',
                        '–∫–æ–Ω—Ñ–ª–∏–∫—Ç', '—Å–ø–æ—Ä', '–Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏–µ', '–æ–±–∏–¥–∞', '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ', '—Å—Ç—Ä–µ—Å—Å'],
            
            '–ø–æ–¥–¥–µ—Ä–∂–∫–∞': ['–ø–æ–º–æ—â—å', '–ø–æ–¥–¥–µ—Ä–∂–∫–∞', '—Å–æ–≤–µ—Ç', '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è', '–ø–æ–¥—Å–∫–∞–∑–∫–∞',
                         '—Å–æ–¥–µ–π—Å—Ç–≤–∏–µ', '–≤–∑–∞–∏–º–æ–ø–æ–º–æ—â—å', '–∑–∞–±–æ—Ç–∞', '–≤–Ω–∏–º–∞–Ω–∏–µ', '–ø–æ–Ω–∏–º–∞–Ω–∏–µ'],
            
            '—Ä–∞–¥–æ—Å—Ç—å': ['—Ä–∞–¥–æ—Å—Ç—å', '—Å—á–∞—Å—Ç—å–µ', '—É—Å–ø–µ—Ö', '–ø–æ–±–µ–¥–∞', '–¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ', '–ø—Ä–∞–∑–¥–Ω–∏–∫',
                       '–ø–æ–¥–∞—Ä–æ–∫', '—Å—é—Ä–ø—Ä–∏–∑', '–≤–æ—Å—Ç–æ—Ä–≥', '–≤–æ—Å—Ö–∏—â–µ–Ω–∏–µ', '–≥–æ—Ä–¥–æ—Å—Ç—å']
        }
        
        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç–µ–º
        self.emotion_patterns = {
            '–∫–æ–Ω—Ñ–ª–∏–∫—Ç': ['—Ç—ã –≤–∏–Ω–æ–≤–∞—Ç', '–ø–æ—á–µ–º—É —Ç—ã', '–æ–ø—è—Ç—å —Ç—ã', '–≤–µ—á–Ω–æ —Ç—ã', '–Ω–µ –º–æ–≥—É –±–æ–ª—å—à–µ'],
            '–ø–æ–¥–¥–µ—Ä–∂–∫–∞': ['–≤—Å—ë –±—É–¥–µ—Ç —Ö–æ—Ä–æ—à–æ', '—è –ø–æ–º–æ–≥—É', '–Ω–µ –ø–µ—Ä–µ–∂–∏–≤–∞–π', '—è —Å —Ç–æ–±–æ–π', '–¥–µ—Ä–∂–∏—Å—å'],
            '–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å': ['—Å–ø–∞—Å–∏–±–æ', '–±–ª–∞–≥–æ–¥–∞—Ä—é', '—Ü–µ–Ω—é', '–ø—Ä–∏–∑–Ω–∞—Ç–µ–ª–µ–Ω', '–æ–±—è–∑–∞–Ω'],
            '–ø—Ä–æ—Å—å–±–∞': ['–ø–æ–∂–∞–ª—É–π—Å—Ç–∞', '–º–æ–≥ –±—ã —Ç—ã', '–Ω–µ –º–æ–≥ –±—ã', '–ø–æ–º–æ–≥–∏', '—Å–¥–µ–ª–∞–π'],
            '–∏–∑–≤–∏–Ω–µ–Ω–∏–µ': ['–∏–∑–≤–∏–Ω–∏', '–ø—Ä–æ—Å—Ç–∏', '–≤–∏–Ω–æ–≤–∞—Ç', '—Å–æ–∂–∞–ª–µ—é', ' pardon']
        }
    
    def extract_topics_from_text(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–º—ã –∏–∑ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        text = text.lower()
        found_topics = []
        
        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–µ–º
        for topic, keywords in self.topic_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    found_topics.append(topic)
                    break  # –ù–∞—à–ª–∏ —Ö–æ—Ç—å –æ–¥–Ω–æ —Å–ª–æ–≤–æ - —Ç–µ–º–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
        
        # –ò—â–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for emotion, patterns in self.emotion_patterns.items():
            for pattern in patterns:
                if pattern in text:
                    found_topics.append(emotion)
                    break
        
        return list(set(found_topics))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
    
    def analyze_dialog_topics(self, messages, participants=None):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–º—ã –≤—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞"""
        all_topics = []
        topics_by_participant = {}
        
        if participants:
            for participant in participants:
                topics_by_participant[participant] = []
        
        for message in messages:
            text = message.get('text', '')
            sender = message.get('sender', '')
            
            message_topics = self.extract_topics_from_text(text)
            all_topics.extend(message_topics)
            
            if sender in topics_by_participant:
                topics_by_participant[sender].extend(message_topics)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É —Ç–µ–º
        topic_frequencies = Counter(all_topics)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —Ç–µ–º—ã (–±–æ–ª—å—à–µ 2 —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)
        dominant_topics = []
        for topic, count in topic_frequencies.most_common(5):
            if count >= 2:  # –ú–∏–Ω–∏–º—É–º 2 —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
                percentage = (count / len(all_topics)) * 100 if all_topics else 0
                dominant_topics.append({
                    'topic': topic,
                    'count': count,
                    'percentage': round(percentage, 1)
                })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω—Ç–µ—Ä–µ—Å—ã —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
        participant_interests = {}
        for participant, topics in topics_by_participant.items():
            if topics:
                topic_counter = Counter(topics)
                main_topic = topic_counter.most_common(1)[0][0] if topic_counter else '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
                participant_interests[participant] = {
                    'main_interest': main_topic,
                    'all_topics': dict(topic_counter)
                }
        
        return {
            'all_topics': dict(topic_frequencies),
            'dominant_topics': dominant_topics,
            'total_messages_analyzed': len(messages),
            'participant_interests': participant_interests
        }
    
    def get_topic_transitions(self, messages):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Ç–µ–º–∞–º–∏ –≤ –¥–∏–∞–ª–æ–≥–µ"""
        transitions = []
        previous_topic = None
        
        for i, message in enumerate(messages):
            if i > 0:  # –ù–∞—á–∏–Ω–∞—è —Å–æ –≤—Ç–æ—Ä–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                text = message.get('text', '')
                current_topics = self.extract_topics_from_text(text)
                
                if current_topics and previous_topic:
                    if current_topics[0] != previous_topic:
                        transitions.append({
                            'from': previous_topic,
                            'to': current_topics[0],
                            'message_index': i
                        })
                
                if current_topics:
                    previous_topic = current_topics[0]
        
        return transitions
    
# –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
# if __name__ == "__main__":
#     analyzer = TopicAnalyzer()
    
#     # –¢–µ—Å—Ç–æ–≤—ã–π –¥–∏–∞–ª–æ–≥
#     test_messages = [
#         {"sender": "–ê–ª–µ–∫—Å–µ–π", "text": "–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ, –ò—Ä–∏–Ω–∞. –ù–∞–ø–æ–º–Ω–∏, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –≥–æ—Ç–æ–≤–∞?"},
#         {"sender": "–ò—Ä–∏–Ω–∞", "text": "–î–æ–±—Ä–æ–µ! –ü–æ—á—Ç–∏, –æ—Å—Ç–∞–ª–æ—Å—å –¥–æ–æ—Ñ–æ—Ä–º–∏—Ç—å –¥–∏–∞–≥—Ä–∞–º–º—ã –ø–æ –ø—Ä–æ–µ–∫—Ç—É."},
#         {"sender": "–ê–ª–µ–∫—Å–µ–π", "text": "–ú—ã –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏—Ö –≤—á–µ—Ä–∞ –≤–µ—á–µ—Ä–æ–º. –≠—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞."},
#         {"sender": "–ò—Ä–∏–Ω–∞", "text": "–î–∞, –∏–∑–≤–∏–Ω–∏—Ç–µ. –í–æ–∑–Ω–∏–∫–ª–∏ —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å –æ—Ç—á—ë—Ç–æ–º."},
#         {"sender": "–ê–ª–µ–∫—Å–µ–π", "text": "–õ–∞–¥–Ω–æ, –ø–æ–º–æ–≥—É —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è. –í–º–µ—Å—Ç–µ —Ä–µ—à–∏–º."},
#         {"sender": "–ò—Ä–∏–Ω–∞", "text": "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É!"}
#     ]
    
#     print("üîç –¢–ï–°–¢ –ê–ù–ê–õ–ò–ó–ê –¢–ï–ú:")
#     results = analyzer.analyze_dialog_topics(test_messages, ["–ê–ª–µ–∫—Å–µ–π", "–ò—Ä–∏–Ω–∞"])
    
#     print("üìä –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –¥–∏–∞–ª–æ–≥–∞:")
#     for topic in results['dominant_topics']:
#         print(f"   ‚Ä¢ {topic['topic']}: {topic['count']} —Ä–∞–∑ ({topic['percentage']}%)")
    
#     print("\nüë§ –ò–Ω—Ç–µ—Ä–µ—Å—ã —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤:")
#     for participant, interests in results['participant_interests'].items():
#         print(f"   {participant}: {interests['main_interest']}")
#         print(f"     –í—Å–µ —Ç–µ–º—ã: {interests['all_topics']}")
    
#     print("\nüîÑ –ü–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Ç–µ–º–∞–º–∏:")
#     transitions = analyzer.get_topic_transitions(test_messages)
#     for transition in transitions:
#         print(f"   –°–æ–æ–±—â–µ–Ω–∏–µ {transition['message_index']}: {transition['from']} ‚Üí {transition['to']}")