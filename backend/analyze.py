from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import json
import os
import re
import statistics
from collections import defaultdict
#from topic_analyze import extract_topics_from_dialog  # LLM-—Ñ—É–Ω–∫—Ü–∏—è
from interpret_analyze import interpret_analysis # –§—É–Ω–∫—Ü–∏—è –∞–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞


# ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –í–†–£–ß–ù–£–Æ —Å use_fast=False
print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —ç–º–æ—Ü–∏–π...")
model_name = "cardiffnlp/twitter-xlm-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

emotion_model = pipeline(
    "text-classification",
    model=model,
    tokenizer=tokenizer,
    return_all_scores=True,
    top_k=None
)

def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = re.sub(r'[^\w\s.,!?–∞-—è–ê-–Ø—ë–Å]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text or ""

def get_emotion(text):
    preds = emotion_model(text)[0]
    result = {"negative": 0.0, "neutral": 0.0, "positive": 0.0}
    for p in preds:
        label = p["label"].lower()
        if "neg" in label:
            result["negative"] = round(p["score"], 3)
        elif "neu" in label:
            result["neutral"] = round(p["score"], 3)
        elif "pos" in label:
            result["positive"] = round(p["score"], 3)
    return result

def analyze_participant(sender, messages):
    cleaned_messages = []
    texts = []

    for msg in messages:
        raw_text = msg.get("text")
        if not raw_text:
            continue
        clean = clean_text(raw_text)
        if not clean:
            continue
        cleaned_messages.append((msg, clean))
        texts.append(clean)

    if not texts:
        return {
            "messages_count": 0,
            "emotions_median": {"negative": 0.0, "neutral": 0.0, "positive": 0.0},
            "topics": [],
            "messages": []
        }

    # –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π
    emotions_total = defaultdict(list)
    messages_out = []

    for orig_msg, clean_txt in cleaned_messages:
        e = get_emotion(clean_txt)
        for k, v in e.items():
            emotions_total[k].append(v)
        messages_out.append({
            "text": orig_msg["text"],
            "time": orig_msg.get("time"),
            "emotion_scores": e
        })

    emotions_median = {k: round(statistics.median(vs), 3) for k, vs in emotions_total.items()}
    for k in ["negative", "neutral", "positive"]:
        emotions_median.setdefault(k, 0.0)

    # üî• –ü–æ–ª—É—á–∞–µ–º —Ç–µ–º—ã —á–µ—Ä–µ–∑ LLM (—Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—Å—Ç–∞–º —ç—Ç–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞)
    # try:
    #     participant_topics = extract_topics_from_dialog(messages)
    # except Exception as e:
    #     print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM –¥–ª—è {sender}: {e}")
    #     participant_topics = ["–æ—à–∏–±–∫–∞_—Ç–µ–º—ã"]

    return {
        "messages_count": len(messages_out),
        "emotions_median": emotions_median,
        #"topics": participant_topics,  # ‚Üê —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
        "messages": messages_out
    }

def analyze_dialog_by_participant(dialog_path):
    try:
        with open(dialog_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as e:
        return {"error": f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {dialog_path}: {e}"}

    messages = data.get("messages", [])
    if not messages:
        return {"dialog_id": data.get("dialog_id") or data.get("id"), "error": "–ü—É—Å—Ç–æ–π –¥–∏–∞–ª–æ–≥"}

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è–º
    grouped = {}
    for msg in messages:
        sender = msg.get("sender")
        if sender:
            grouped.setdefault(sender, []).append(msg)

    participants_data = {}
    for sender, msgs in grouped.items():
        try:
            participants_data[sender] = analyze_participant(sender, msgs)
        except Exception as e:
            participants_data[sender] = {"error": str(e)}

    # # üî• –¢–µ–º—ã –¥–ª—è –í–°–ï–ì–û –¥–∏–∞–ª–æ–≥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    # try:
    #     dialog_topics = extract_topics_from_dialog(messages)
    # except Exception as e:
    #     print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM –Ω–∞ –≤—Å—ë–º –¥–∏–∞–ª–æ–≥–µ: {e}")
    #     dialog_topics = ["–æ—à–∏–±–∫–∞_—Ç–µ–º—ã"]

    return {
        "dialog_id": data.get("dialog_id") or data.get("id"),
        "title": data.get("title"),
        # "dialog_topics": dialog_topics,           # —Ç–µ–º—ã –≤—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞
        "participants_analysis": participants_data
    }

def main():
    out_dir = "/home/fedosdan2/prog/pr_act/PROJECT/backend/analysis_results"
    os.makedirs(out_dir, exist_ok=True)

    fpath = "/home/fedosdan2/prog/pr_act/PROJECT/backend/dialogs/2.json"
    f = os.path.basename(fpath)
    res = analyze_dialog_by_participant(fpath)

    out_path = os.path.join(out_dir, f"{os.path.splitext(f)[0]}_analysis.json")
    with open(out_path, "w", encoding="utf-8") as out:
        json.dump(res, out, indent=2, ensure_ascii=False)

    print(f"‚úÖ {f} ‚Üí —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {out_path}")

    # üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ—à—ë–ª —É—Å–ø–µ—à–Ω–æ
    if "error" in res:
        print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏: {res['error']}")
        return

    try:
        interpretation = interpret_analysis(res)
        print("\nüß† –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:")
        print(interpretation)

        interp_path = os.path.join(out_dir, f"{os.path.splitext(f)[0]}_interpretation.txt")
        with open(interp_path, "w", encoding="utf-8") as f_out:
            f_out.write(interpretation)
        print(f"üìÑ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {interp_path}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏: {e}")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥–ª—É—à–∫—É
        interp_path = os.path.join(out_dir, f"{os.path.splitext(f)[0]}_interpretation.txt")
        with open(interp_path, "w", encoding="utf-8") as f_out:
            f_out.write(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏: {e}")

if __name__ == "__main__":
    main()